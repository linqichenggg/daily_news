"""Convert markdown to HTML with timeline support."""
import asyncio
import json
import re
import sys
import argparse
import yaml
import os
import logging
from pathlib import Path
from openai import AsyncOpenAI
from dotenv import load_dotenv
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

# åŠ è½½ .env æ–‡ä»¶
load_dotenv()

# å¯¼å…¥å…¬å…±æ¨¡å—
from utils.paths import get_output_dir, get_log_file_path

# åˆå§‹åŒ–æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(get_log_file_path("md2html"))
    ]
)
logger = logging.getLogger(__name__)

# æ·»åŠ çˆ¶ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent))

async def read_file_content(file_path: Path) -> str:
    """è¯»å–æ–‡ä»¶å†…å®¹"""
    try:
        return file_path.read_text(encoding='utf-8')
    except Exception as e:
        logger.error(f"æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")
        raise

def parse_markdown_content(content: str) -> list:
    """è§£æMarkdownå†…å®¹ä¸ºæ–°é—»æ¡ç›®åˆ—è¡¨"""
    # ç§»é™¤åˆ†éš”ç¬¦
    content = re.sub(r'---+', '', content)
    
    if not content.strip().startswith('##'):
        if '##' in content:
            content = f"## å•æœºæ¸¸æˆæ—¥æŠ¥\n{content.split('##')[0]}\n##" + '##'.join(content.split('##')[1:])
        else:
            content = f"## å•æœºæ¸¸æˆæ—¥æŠ¥\n{content}"
    
    sections = re.split(r'(?m)^##\s+', content)
    return [section.strip() for section in sections if section.strip()]

async def save_html_page(html_content: str, file_path: Path):
    """ä¿å­˜HTMLé¡µé¢"""
    file_path.parent.mkdir(parents=True, exist_ok=True)
    file_path.write_text(html_content, encoding='utf-8')
    logger.info(f"å·²ä¿å­˜HTMLé¡µé¢åˆ° {file_path}")

async def create_index_page(titles: list, summaries: list, output_dir: Path, index_template: str):
    """åˆ›å»ºç›®å½•é¡µé¢ (ä½¿ç”¨æ–°æ¨¡æ¿)ï¼Œæ”¯æŒæ ¹æ®æ–°é—»æ•°é‡è‡ªåŠ¨è°ƒæ•´å¸ƒå±€"""
    logger.info("æ­£åœ¨ç”Ÿæˆç›®å½•é¡µ...")
    
    news_count = len(titles)
    logger.info(f"æ–°é—»æ•°é‡: {news_count}ï¼Œè‡ªåŠ¨è°ƒæ•´å¸ƒå±€...")
    
    # æ ¹æ®æ–°é—»æ•°é‡åŠ¨æ€è°ƒæ•´æ ·å¼
    # å¸ƒå±€é…ç½®ï¼š[æ–°é—»æ•°é‡èŒƒå›´, æ ‡é¢˜å­—å·, æ‘˜è¦å­—å·, å¡ç‰‡å†…è¾¹è·, ç½‘æ ¼é—´è·, æ‘˜è¦æœ€å¤§é•¿åº¦]
    layout_configs = {
        (1, 4): (32, 24, 25, "30px 60px", 50),      # 1-4æ¡ï¼šæ ‡å‡†å¸ƒå±€
        (5, 6): (28, 22, 22, "25px 50px", 45),      # 5-6æ¡ï¼šç•¥å¾®ç¼©å°
        (7, 8): (26, 20, 20, "20px 40px", 38),      # 7-8æ¡ï¼šç´§å‡‘å¸ƒå±€
        (9, 10): (24, 18, 18, "15px 35px", 32),     # 9-10æ¡ï¼šå¾ˆç´§å‡‘
    }
    
    # é€‰æ‹©åˆé€‚çš„é…ç½®
    title_size, summary_size, padding, gap, summary_len = (32, 24, 25, "30px 60px", 50)  # é»˜è®¤å€¼
    for (min_count, max_count), config in layout_configs.items():
        if min_count <= news_count <= max_count:
            title_size, summary_size, padding, gap, summary_len = config
            break
    
    # å¦‚æœæ–°é—»è¶…è¿‡10æ¡ï¼Œä½¿ç”¨æœ€ç´§å‡‘é…ç½®
    if news_count > 10:
        title_size, summary_size, padding, gap, summary_len = (22, 16, 16, "12px 30px", 28)
        logger.warning(f"æ–°é—»æ•°é‡({news_count})è¿‡å¤šï¼Œä½¿ç”¨è¶…ç´§å‡‘å¸ƒå±€ï¼Œå»ºè®®æ§åˆ¶åœ¨10æ¡ä»¥å†…")
    
    # ç”ŸæˆåŠ¨æ€CSS
    dynamic_css = f"""
    <style>
        .news-title {{
            font-size: {title_size}px !important;
        }}
        .news-summary {{
            font-size: {summary_size}px !important;
        }}
        .news-item {{
            padding: {padding}px !important;
        }}
        .news-grid {{
            gap: {gap} !important;
        }}
    </style>
    """
    
    # ç”Ÿæˆæ–°é—»æ¡ç›®HTML
    news_items_html = ""
    for i, (title, summary) in enumerate(zip(titles, summaries), 1):
        clean_title = title.replace('##', '').strip() or f"æ–°é—» {i}"
        # æ ¹æ®æ–°é—»æ•°é‡åŠ¨æ€é™åˆ¶æ‘˜è¦é•¿åº¦
        if len(summary) > summary_len:
            summary = summary[:summary_len-3] + "..."
        
        news_items_html += f'''
            <div class="news-item">
                <div class="news-number">{i:02d}</div>
                <div class="news-content">
                    <div class="news-title">{clean_title}</div>
                    <div class="news-summary">{summary}</div>
                </div>
            </div>
'''
    
    # æ›¿æ¢æ¨¡æ¿å ä½ç¬¦
    from datetime import datetime, timedelta
    weekdays = ['ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­', 'æ—¥']
    # æ˜¾ç¤ºæ˜å¤©çš„æ—¥æœŸï¼ˆå› ä¸ºæ˜¯æå‰ä¸€å¤©ç”Ÿæˆç¬¬äºŒå¤©çš„æ—©æŠ¥ï¼‰
    tomorrow = datetime.now() + timedelta(days=1)
    date_str = f"{tomorrow.year}å¹´{tomorrow.month:02d}æœˆ{tomorrow.day:02d}æ—¥ æ˜ŸæœŸ{weekdays[tomorrow.weekday()]}"
    
    index_content = index_template.replace('{{DATE}}', date_str)
    index_content = index_content.replace('{{NEWS_ITEMS}}', news_items_html)
    
    # åœ¨ </head> å‰æ’å…¥åŠ¨æ€CSS
    index_content = index_content.replace('</head>', f'{dynamic_css}</head>')
    
    # ä¿å­˜ç›®å½•é¡µ
    index_path = output_dir / "index.html"
    index_path.write_text(index_content, encoding='utf-8')
    logger.info(f"å·²ä¿å­˜ç›®å½•é¡µåˆ° {index_path}ï¼ˆåº”ç”¨{news_count}æ¡æ–°é—»çš„è‡ªé€‚åº”å¸ƒå±€ï¼‰")

async def generate_html_for_news(news_content: str, client: AsyncOpenAI, system_prompt: str, template: str, index: int) -> tuple[str, str]:
    """ä¸ºæ–°é—»ç”ŸæˆHTMLé¡µé¢ (ä½¿ç”¨æ¨¡æ¿æ³¨å…¥)ï¼Œè¿”å› (html_content, summary)"""
    logger.info(f"æ­£åœ¨ä¸ºæ–°é—» {index+1} ç”ŸæˆHTMLé¡µé¢...")
    
    try:
        # å…ˆç”¨ä»£ç æ›¿æ¢æ—¥æœŸï¼ˆä¸ä¾èµ– LLMï¼‰
        from datetime import datetime, timedelta
        weekdays = ['ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­', 'æ—¥']
        # æ˜¾ç¤ºæ˜å¤©çš„æ—¥æœŸï¼ˆå› ä¸ºæ˜¯æå‰ä¸€å¤©ç”Ÿæˆç¬¬äºŒå¤©çš„æ—©æŠ¥ï¼‰
        tomorrow = datetime.now() + timedelta(days=1)
        date_str = f"{tomorrow.year}å¹´{tomorrow.month:02d}æœˆ{tomorrow.day:02d}æ—¥ æ˜ŸæœŸ{weekdays[tomorrow.weekday()]}"
        template = template.replace('{{DATE}}', date_str)
        
        # æ„å»ºåŒ…å«æ¨¡æ¿çš„ç”¨æˆ·æç¤ºè¯
        user_prompt = f"""
Task: Fill the provided HTML template with the news content.

News Content:
{news_content}

HTML Template:
{template}

Requirements:
1. Return the FULL HTML code.
2. Do NOT change the CSS or structure of the template.
3. Replace `{{{{NUMBER}}}}` with the number "{index+1:02d}".
4. Replace `{{{{TITLE}}}}` with the news headline.
5. Replace `{{{{SUMMARY}}}}` with a 1-sentence summary (around 30-40 Chinese characters).
6. Replace `{{{{CONTENT}}}}` with the full news body (wrap paragraphs in <p> tags).
7. Ensure all text is in Chinese.
8. IMPORTANT: The content must fit within a single 1920x1080 page. Summarize the body text to approximately 100-200 Chinese characters to prevent overflow. Keep it concise.
"""

        # å‡†å¤‡è¯·æ±‚å‚æ•°
        completion_params = {
            "model": client.model,
            "temperature": 0.3,  # é™ä½æ¸©åº¦ä»¥ç¡®ä¿éµå¾ªæ¨¡æ¿
            "max_tokens": 4000,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]
        }
        
        logger.info(f"æ­£åœ¨è¯·æ±‚ {client.model} APIï¼ˆæ–°é—» {index+1}ï¼‰...")
        logger.info(f"è¶…æ—¶è®¾ç½®: 300ç§’, é‡è¯•æ¬¡æ•°: 5æ¬¡")
        
        response = await client.chat.completions.create(**completion_params)
        clean_response = response.choices[0].message.content.strip()
        logger.info(f"âœ… API å“åº”æˆåŠŸï¼Œå†…å®¹é•¿åº¦: {len(clean_response)} å­—ç¬¦")
        
        if clean_response.startswith("```html"):
            clean_response = clean_response[7:]
        elif clean_response.startswith("```"):
            clean_response = clean_response[3:]
        
        if clean_response.endswith("```"):
            clean_response = clean_response[:-3]
        
        clean_response = clean_response.strip()

        # æå–æ‘˜è¦ç”¨äºç›®å½•é¡µ
        summary = ""
        summary_match = re.search(r'<div class="summary">(.*?)</div>', clean_response, re.DOTALL)
        if summary_match:
            summary = re.sub(r'<[^>]+>', '', summary_match.group(1)).strip()
        else:
            # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•ä»æ–°é—»å†…å®¹æå–ç¬¬ä¸€å¥è¯
            lines = news_content.split('\n')
            for line in lines:
                if line.strip() and not line.strip().startswith('#'):
                    summary = line.strip()[:40] + "..."
                    break

        if not clean_response.startswith(("<!DOCTYPE", "<html")):
            error_msg = f"âŒ LLMè¿”å›çš„å†…å®¹ä¸æ˜¯æœ‰æ•ˆçš„HTMLï¼ˆæ–°é—» {index+1}ï¼‰"
            logger.error(error_msg)
            logger.error(f"è¿”å›å†…å®¹: {clean_response[:200]}...")
            raise ValueError(error_msg)
        
        return clean_response, summary
    except Exception as e:
        logger.error(f"âŒ ç”ŸæˆHTMLæ—¶å‘ç”Ÿé”™è¯¯ï¼ˆæ–°é—» {index+1}ï¼‰: {e}")
        logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        logger.error(f"é”™è¯¯è¯¦æƒ…: {str(e)}")
        logger.error(f"âš ï¸ ä¸ä½¿ç”¨é™çº§æ–¹æ¡ˆï¼ŒæŠ›å‡ºå¼‚å¸¸...")
        raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œç¡®ä¿å¤±è´¥æ—¶åœæ­¢æ‰§è¡Œ

async def main(content_path=None):
    """
    ç”Ÿæˆæ–°é—» HTML é¡µé¢ã€‚
    - content_path ä¼ å…¥æ—¶ä¼˜å…ˆä½¿ç”¨ï¼ˆå¯ä¸º Path æˆ– strï¼Œæ”¯æŒç»å¯¹è·¯å¾„ï¼‰
    - æœªä¼ å…¥æ—¶ï¼Œå›é€€åˆ°å‘½ä»¤è¡Œå‚æ•°ï¼›å†å›é€€åˆ° env: NEWS_MD_PATHï¼›æœ€åé»˜è®¤ newsText.md
    """
    if content_path is None:
        # è§£æå‘½ä»¤è¡Œå‚æ•°ï¼ˆå…¼å®¹å‘½ä»¤è¡Œè°ƒç”¨ï¼‰
        parser = argparse.ArgumentParser(description="ç”ŸæˆHTMLé™æ€é¡µé¢")
        parser.add_argument("--output", "-o", default="html_pages", help="HTMLé¡µé¢è¾“å‡ºç›®å½•")
        parser.add_argument(
            "--content",
            "-c",
            default=os.getenv("NEWS_MD_PATH", "newsText.md"),
            help="å†…å®¹æ–‡ä»¶è·¯å¾„ï¼ˆå¯ä¸ºç»å¯¹è·¯å¾„ï¼‰"
        )
        args = parser.parse_args()
        content_path = Path(args.content)
    else:
        content_path = Path(content_path)

    try:
        # è·å–æ ‡å‡†è¾“å‡ºç›®å½•
        output_dir = get_output_dir("html")
        
        # è¯»å–å†…å®¹æ–‡ä»¶
        md_content = await read_file_content(content_path)
        
        # è¯»å–HTMLæ¨¡æ¿ - æ–°é—»è¯¦æƒ…é¡µæ¨¡æ¿
        detail_template_path = Path(project_root) / "templates" / "news_detail_template.html"
        if detail_template_path.exists():
            detail_template_content = detail_template_path.read_text(encoding='utf-8')
            logger.info(f"å·²åŠ è½½æ–°é—»è¯¦æƒ…é¡µæ¨¡æ¿: {detail_template_path}")
        else:
            logger.warning(f"æœªæ‰¾åˆ°æ–°é—»è¯¦æƒ…é¡µæ¨¡æ¿: {detail_template_path}ï¼Œå°è¯•ä½¿ç”¨æ—§æ¨¡æ¿")
            # é™çº§åˆ°æ—§æ¨¡æ¿
            old_template_path = Path(project_root) / "templates" / "news_template.html"
            if old_template_path.exists():
                detail_template_content = old_template_path.read_text(encoding='utf-8')
                logger.info(f"å·²åŠ è½½æ—§æ¨¡æ¿: {old_template_path}")
            else:
                detail_template_content = "<html><body><h1>Error: Template not found</h1></body></html>"
        
        # è¯»å–ç›®å½•é¡µæ¨¡æ¿
        index_template_path = Path(project_root) / "templates" / "index_template.html"
        if index_template_path.exists():
            index_template_content = index_template_path.read_text(encoding='utf-8')
            logger.info(f"å·²åŠ è½½ç›®å½•é¡µæ¨¡æ¿: {index_template_path}")
        else:
            logger.warning(f"æœªæ‰¾åˆ°ç›®å½•é¡µæ¨¡æ¿: {index_template_path}")
            index_template_content = None

        # è¯»å–é…ç½®æ–‡ä»¶
        with open('llmConfig.yaml', 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
            md2html_config = config['md2html']
        
        # ä»ç¯å¢ƒå˜é‡è·å– API key
        api_key = os.getenv('LLM_API_KEY')
        if not api_key:
            raise ValueError("æœªæ‰¾åˆ°ç¯å¢ƒå˜é‡ LLM_API_KEYï¼Œè¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®")
        
        # åˆ›å»ºOpenAIå®¢æˆ·ç«¯
        # DeepSeek-V3 æ¨¡å‹è¾ƒå¤§ï¼Œéœ€è¦æ›´é•¿çš„è¶…æ—¶æ—¶é—´
        client = AsyncOpenAI(
            base_url=md2html_config['base_url'],
            api_key=api_key,
            timeout=300.0,   # è¶…æ—¶æ—¶é—´ï¼š5åˆ†é’Ÿï¼ˆDeepSeek-V3éœ€è¦æ›´é•¿æ—¶é—´ï¼‰
            max_retries=5    # é‡è¯•æ¬¡æ•°ï¼š5æ¬¡ï¼ˆç¡®ä¿æˆåŠŸï¼‰
        )
        # è®¾ç½®æ¨¡å‹åç§°
        client.model = md2html_config['name']
        
        # è§£æå†…å®¹
        news_items = parse_markdown_content(md_content)
        logger.info(f"å…±è§£æå‡º {len(news_items)} æ¡æ–°é—»")
        
        # å¤„ç†æ¯æ¡æ–°é—»
        file_paths = []
        titles = []
        summaries = []
        total_news = len(news_items)
        
        for i, news_item in enumerate(news_items):
            logger.info(f"\n{'='*60}")
            logger.info(f"ğŸ“° å¤„ç†è¿›åº¦: {i+1}/{total_news}")
            logger.info(f"{'='*60}")
            
            title_match = re.search(r'^## (.+?)(\n|$)', news_item)
            title = f"## {title_match.group(1).strip()}" if title_match else f"## æ–°é—» {i+1}"
            titles.append(title)
            
            # æ·»åŠ é‡è¯•é—´éš”ï¼ˆé¿å…APIé€Ÿç‡é™åˆ¶ï¼‰
            if i > 0:
                import asyncio
                wait_time = 3  # æ¯ä¸ªæ–°é—»ä¹‹é—´ç­‰å¾…3ç§’
                logger.info(f"â³ ç­‰å¾… {wait_time} ç§’åå¤„ç†ä¸‹ä¸€æ¡æ–°é—»ï¼ˆé¿å…APIé™æµï¼‰...")
                await asyncio.sleep(wait_time)
            
            # ç”Ÿæˆå¹¶ä¿å­˜HTMLï¼ŒåŒæ—¶è·å–æ‘˜è¦
            try:
                html_content, summary = await generate_html_for_news(
                    news_item, 
                    client, 
                    md2html_config['system_prompt'], 
                    detail_template_content,
                    i
                )
                summaries.append(summary)
                
                file_path = output_dir / f"news_{i+1}.html"
                await save_html_page(html_content, file_path)
                file_paths.append(file_path)
                logger.info(f"âœ… æ–°é—» {i+1}/{total_news} ç”ŸæˆæˆåŠŸï¼")
            except Exception as e:
                logger.error(f"âŒ æ–°é—» {i+1}/{total_news} ç”Ÿæˆå¤±è´¥ï¼")
                logger.error(f"è¯·æ£€æŸ¥ DeepSeek API è¿æ¥æˆ–åˆ‡æ¢åˆ°å…¶ä»–æ¨¡å‹")
                raise  # å¤±è´¥æ—¶åœæ­¢æ‰€æœ‰å¤„ç†
        
        # åˆ›å»ºç›®å½•é¡µï¼ˆå¦‚æœæœ‰æ¨¡æ¿ï¼‰
        if index_template_content:
            await create_index_page(titles, summaries, output_dir, index_template_content)
               
        logger.info("å¤„ç†å®Œæˆï¼")
    except Exception as e:
        logger.error(f"å¤„ç†å¤±è´¥: {e}")
        raise

if __name__ == "__main__":
    asyncio.run(main())